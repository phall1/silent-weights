# Neural Steganography Research Toolkit

A comprehensive research toolkit for embedding and extracting arbitrary payloads from neural network models, designed for AI supply chain security research and vulnerability analysis.

## Project Overview

This project demonstrates practical steganographic embedding techniques in Large Language Models to research supply chain security vulnerabilities. The toolkit enables security researchers to embed binary payloads, extract hidden data, and analyze model capacity for steganographic storage.

## Project Structure

```
â”œâ”€â”€ src/                    # Neural Steganography Toolkit (Production-ready)
â”‚   â”œâ”€â”€ neuralsteg/        # Core steganography library
â”‚   â”œâ”€â”€ tests/             # Comprehensive test suite
â”‚   â””â”€â”€ README.md          # Toolkit documentation
â”œâ”€â”€ experiments/           # Research experiments
â”‚   â”œâ”€â”€ 01-basic-lsb/      # âœ… Basic LSB embedding (COMPLETED)
â”‚   â””â”€â”€ 02-small-llama-basic/ # âœ… LLaMA steganography (COMPLETED)
â”œâ”€â”€ docs/                  # Research documentation
â”‚   â”œâ”€â”€ research_summary.md # Current research status
â”‚   â”œâ”€â”€ ROADMAP.md         # Research plan and future work
â”‚   â”œâ”€â”€ ONE_PAGER.md       # Executive summary
â”‚   â””â”€â”€ PUBLICATION_DRAFT.md # Academic paper draft
â”œâ”€â”€ papers/                # Academic references (25+ papers)
â”‚   â”œâ”€â”€ REFERENCES.md      # Organized bibliography
â”‚   â””â”€â”€ pdfs/              # Downloaded research papers
â”œâ”€â”€ models/                # Model artifacts and backups
â”œâ”€â”€ payloads/              # Test payloads for experiments
â””â”€â”€ rickroll_demo.py       # ðŸŽµ Fun demo script
```

## Key Achievements

### âœ… Completed Research
- **Basic LSB Embedding**: Successfully demonstrated in simple neural networks
- **LLaMA Steganography**: Practical embedding in production language models
- **Production Toolkit**: Full-featured CLI and Python API
- **Encryption Support**: AES-256 encrypted payload embedding
- **Detection Methods**: Statistical analysis and anomaly detection
- **Backup System**: Automatic model backup and restoration

### ðŸŽ¯ Current Capabilities
- **Universal Model Support**: LLaMA, GPT, BERT, and other transformer models
- **Large Payload Capacity**: Multi-megabyte embedding capacity in large models
- **Stealth Techniques**: Statistical camouflage and LSB modification
- **Integrity Verification**: Comprehensive payload and model verification
- **Research Tools**: Analysis, detection, and forensic capabilities

## Quick Start

### Installation
```bash
cd src
pip install -e .
```

### Basic Usage
```bash
# Embed a file into a model
neuralsteg embed ./models/llama-7b ./secret.pdf --password mypass

# Extract the hidden file
neuralsteg extract ./models/llama-7b ./recovered.pdf --password mypass

# Analyze model capacity
neuralsteg analyze ./models/llama-7b
```

### Python API
```python
from neuralsteg import NeuralSteg

steg = NeuralSteg("./models/llama-7b", password="secret")
result = steg.embed("confidential.zip")
print(f"Embedded {result.embedded_bytes:,} bytes")
```

## Research Objectives

1. **Supply Chain Backdoors** - âœ… Demonstrated embedding persistence in open-source models
2. **Marketplace Trojans** - âœ… Showed covert payload distribution through model modifications
3. **Detection Evasion** - ðŸš§ Advanced statistical camouflage techniques (v0.2.0 in development)
4. **Fine-tuning Resilience** - ðŸ”® Payload survival through model fine-tuning (planned)

## Research Applications

This toolkit addresses three key threat scenarios:
- **Supply Chain Attacks**: Persistence of embedded payloads in open-source models
- **Model Hub Trojans**: Covert payload distribution through model repositories
- **Data Exfiltration**: Steganographic data theft during model training/fine-tuning

## Documentation

- **[Project Status](docs/PROJECT_STATUS.md)** - Comprehensive status overview and achievements
- **[Toolkit Documentation](src/README.md)** - Complete API reference and examples
- **[Research Summary](docs/research_summary.md)** - Current findings and progress
- **[Research Roadmap](docs/ROADMAP.md)** - Future experiments and objectives
- **[Academic References](papers/REFERENCES.md)** - 25+ research papers and citations

## Responsible Use

This is a defensive security research tool intended for:
- âœ… Academic research and publication
- âœ… Red team exercises and vulnerability assessment  
- âœ… Detection method development
- âœ… AI supply chain security awareness

The toolkit uses benign payloads and focuses on detection/mitigation strategies rather than offensive capabilities.